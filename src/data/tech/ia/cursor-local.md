---
title: "Cursor Local : L'Assistant de Code Open Source"
description: "Guide pratique pour configurer et utiliser le mod√®le IA Quen 2.5 avec l'√©diteur de code Cursor en local. D√©couvre comment coder plus efficacement avec une IA open source."
pubDate: "2024-03-25"
category: "Tech"
author: "Web'Ind√©"
imgUrl: "../../../assets/astro.jpeg"
tags:
  - IA
  - Code
  - Open Source
---

# CURSOR LOCAL : Utilise ton Assistant de Code en Local ou avec Gaia

## Deux Approches pour un Code Plus Priv√©

Tu as deux options principales pour utiliser Cursor avec des mod√®les locaux ou semi-locaux :

1. **üè† 100% Local avec LM Studio + Ngrok ou Gaia**
   - Installation locale compl√®te
   - Contr√¥le total sur tes donn√©es
   - N√©cessite plus de ressources

2. **üåê Semi-Local avec Gaia**
   - Service d√©centralis√©
   - Configuration plus simple
   - Performance optimis√©e

## Pr√©requis Syst√®me pour les Mod√®les Locaux

### üñ•Ô∏è Configuration Recommand√©e

Selon la [documentation officielle de Gaia](https://docs.gaianet.ai/getting-started/system-requirements), tu auras besoin de :

- **Pour Mac** :
  - Apple Silicon (M1 √† M4)
  - 16 Go RAM minimum (32 Go recommand√©s)
  - macOS r√©cent

- **Pour Linux** :
  - Ubuntu 22.04 (recommand√©)
  - NVIDIA CUDA 12 SDK
  - GPU avec 8 Go VRAM minimum (24 Go recommand√©s)
  - Ex: GPU NVIDIA T4 ou sup√©rieur

### üõ†Ô∏è Configuration Commune aux Deux Approches

Que tu choisisses LM Studio ou Gaia, tu auras besoin de :
- Un tunnel HTTPS (Ngrok ou alternative)
- Une connexion Internet stable
- Cursor install√© et configur√©

## Option 1 : Configuration avec LM Studio + Ngrok

1. **Installation des Outils**
   ```bash
   # Sur macOS avec Homebrew
   brew install --cask ngrok
   brew install --cask lm-studio
   ```

2. **Configuration du Tunnel**
   ```bash
   # Lance LM Studio et d√©marre le serveur sur le port 1234
   ngrok http 1234
   ```

3. **Configuration de Cursor**
   ```bash
   # Dans Cursor, utilise l'URL fournie par Ngrok
   Base URL: https://ton-tunnel.ngrok.io/v1
   API Key: "DEMO" # n'importe quelle valeur
   ```

## Utiliser Ngrok pour exposer le serveur local

- Malheureusement, Cursor ne peut pas acc√©der directement √† ton serveur local, car il route les requ√™tes vers ses propres serveurs.
- Nous allons donc utiliser Ngrok pour exposer ton serveur local √† travers un endpoint public.
- Installe Ngrok sur ta machine (par exemple avec Homebrew sur macOS) et lance la commande `ngrok http 1234` pour cr√©er un tunnel vers ton serveur.

### üîí Comprendre Ngrok et ses Alternatives

Ngrok est un outil populaire qui permet d'exposer un serveur web local √† Internet. Il cr√©e un tunnel s√©curis√© entre Internet et ta machine locale, fournissant une URL unique que tu peux partager.

#### Fonctionnalit√©s Cl√©s de Ngrok

1. **Tunneling S√©curis√©** : Cr√©e un tunnel s√©curis√© entre ton serveur web local et Internet
2. **H√©bergement de Sous-domaine** : Fournit un sous-domaine unique (ex: `https://ton-domaine.ngrok.io`)
3. **Transfert HTTPS** : Gestion automatique du HTTPS pour des connexions s√©curis√©es
4. **Inspection du Trafic** : Interface web pour visualiser et d√©boguer le trafic

#### üîÑ Alternatives Gratuites √† Ngrok

1. **Localtunnel**
   - Outil gratuit et open-source
   - Fonctionnalit√©s similaires √† Ngrok
   - Cr√©ation simple de tunnel s√©curis√©

2. **Serveo**
   - Alternative gratuite √† Ngrok
   - Interface en ligne de commande simple
   - Support HTTP et HTTPS

3. **Inlets**
   - Proxy inverse open-source
   - Plus complexe mais plus flexible
   - Meilleur contr√¥le sur le processus

4. **Cloudflare Tunnel**
   - Anciennement Argo Tunnel
   - Configuration plus complexe
   - Connexion s√©curis√©e et fiable

üí° **Conseil de choix** : Pour choisir ton alternative √† Ngrok, consid√®re :
- La facilit√© d'utilisation
- Les fonctionnalit√©s disponibles
- Le niveau de contr√¥le souhait√©
- Tes besoins sp√©cifiques

## Option 2 : Configuration avec Gaia

Gaia is building an decentralized ecosystem to support AI applications that learn, improve, and grow over time.


01.
Choose from a vast collection of open-source LLMs
02.
Add a knowledge base for specialized inference
03.
Fine-tune your models and deploy at scale

Instantly connect to a specialized network of inference nodes.
Power any LLM application with an OpenAI compatible API
Replace costly inference with a simple Gaia endpoint

### üéØ Pourquoi choisir Gaia ?

- **Confidentialit√©** : Ton code reste dans ton organisation
- **Base de connaissances personnalis√©e** : Adapte l'IA √† ton style de code
- **Performance** : Acc√®s √† des mod√®les puissants sans mat√©riel co√ªteux

### üîÑ Compatibilit√© et Installation

Tu peux installer Gaia sur une grande vari√©t√© d'appareils et de syst√®mes d'exploitation, avec ou sans GPU. Les instructions d'installation et d'exploitation fonctionnent sur des appareils allant du Raspberry Pi aux clusters Nvidia H100 bas√©s sur le cloud, en passant par les MacBooks, les serveurs Linux et les PC Windows.

#### Configurations Recommand√©es pour les Op√©rateurs Institutionnels

Tu as deux options principales :

1. **Configuration Mac**
   - iMac, Mini, Studio ou Pro avec Apple Silicon (M1 √† M4)
   - 16 Go de RAM minimum (32 Go ou plus recommand√©s)

2. **Configuration Linux**
   - Serveur Ubuntu 22.04
   - NVIDIA CUDA 12 SDK install√©
   - Minimum 8 Go de VRAM sur le GPU (24 Go ou plus recommand√©s)
   - Sur AWS et Azure, cela signifie des instances GPU avec au moins une NVIDIA T4

üí° **Note importante** : Si tu h√©berges le n≈ìud chez toi ou au bureau, il doit avoir acc√®s √† Internet pour rejoindre le r√©seau Gaia.

#### Support Multi-Plateforme

Le logiciel Gaia node est con√ßu pour √™tre cross-platform :
- Fonctionne sur diverses architectures CPU et GPU
- D√©tecte automatiquement les pilotes NVIDIA CUDA
- Exploite la puissance des acc√©l√©rateurs GPU sur l'appareil
- Plus de support mat√©riel en cours de d√©veloppement

### ‚öôÔ∏è Mod√®les Disponibles sur Gaia

| Type de Mod√®le | URL de Base | Nom du Mod√®le |
|----------------|-------------|---------------|
| Assistant g√©n√©ral | https://coder.gaia.domains/v1 | coder |
| Sp√©cialiste Rust | https://rustcoder.gaia.domains/v1 | rustcoder |
| Expert Rust | https://rustexpert.gaia.domains/v1 | rustexpert |

### üîß Configuration de Cursor avec Gaia

#### üîë Obtenir une cl√© API Gaia pour un node public

Allez sur https://www.gaianet.ai/gaia-domain-name et clique sur "Connect"



#### Pour un node priv√©




1. **Param√©trage Initial**
   - Ouvre les param√®tres de Cursor (‚öôÔ∏è)
   - Va dans la section "Models"
   - Ajoute un nouveau mod√®le nomm√© "coder"
   - D√©sactive les autres mod√®les (gpt-4, etc.)

2. **Configuration de l'API**
   ```bash
   # Dans Settings > OpenAI API Key
   Base URL: https://coder.gaia.domains/v1
   API Key: "GAIA" # ou n'importe quelle cha√Æne
   ```

3. **V√©rification**
   - Clique sur "Verify" pour tester la connexion
   - Essaie une commande simple pour v√©rifier le fonctionnement

### üí° Astuces d'Utilisation

- **Raccourcis Essentiels**
  - `Cmd/Ctrl + K` : √âditer le code s√©lectionn√©
  - `Cmd/Ctrl + L` : Ouvrir le chat pour poser des questions

- **Cas d'Usage Optimaux**
  ```python
  # Exemple de prompt pour Gaia
  "Optimise cette fonction en suivant les bonnes pratiques Python"
  ```

## Comparaison des Approches (Mise √† jour)

| Crit√®re | LM Studio + Ngrok | Gaia |
|---------|-------------------|------|
| Installation | Complexe (plusieurs outils) | Simple (un seul service) |
| Ressources | Selon hardware local | G√©r√©es par Gaia |
| Confidentialit√© | Via tunnel Ngrok | Via n≈ìuds Gaia |
| Performance | D√©pend du mat√©riel | Stable et optimis√©e |
| Maintenance | Configuration tunnel √† g√©rer | Automatique |

üéØ **Pro tip** : Les deux approches n√©cessitent un tunnel HTTPS. Gaia l'int√®gre nativement, tandis qu'avec LM Studio tu devras g√©rer Ngrok ou une alternative.

## Ressources et Support

- [Documentation Gaia](https://docs.gaianet.ai)
- [Communaut√© Cursor](https://discord.gg/cursor)
- [Guide Vid√©o](lien-vers-la-video)



